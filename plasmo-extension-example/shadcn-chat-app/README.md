# AI Web Dev Assistant

Next.js aplikace pro generovÃ¡nÃ­ React komponent s AI modely (Claude, Ollama). InspirovÃ¡no v0.dev a Relume.

## ğŸš€ Funkce

- **GenerovÃ¡nÃ­ funkÄnÃ­ho kÃ³du**: AI vytvÃ¡Å™Ã­ React komponenty s Tailwind CSS (ne jen textovÃ© popisy)
- **Å½ivÃ½ nÃ¡hled kÃ³du**: AutomatickÃ½ sandbox preview pro TSX/JSX/HTML
- **Multi-provider podpora**: Claude (Anthropic API) + Ollama (local/cloud modely)
- **Model selector**: 11 modelÅ¯ (6 cloud, 5 lokÃ¡lnÃ­ch) optimalizovanÃ½ch pro programovÃ¡nÃ­
- **Code preview akce**: Copy to clipboard, Download, Open in new tab
- **Markdown rendering**: Syntax highlighting (highlight.js) + live preview

## ğŸ“¦ Tech Stack

- **Next.js 15.5.6** (App Router, Edge Runtime)
- **React 19.1.0** + TypeScript
- **AI SDK 4.3.19** (Vercel) - chat hooks
- **Ollama** (ollama-ai-provider 1.2.0)
- **Anthropic** (@ai-sdk/anthropic 1.0.0)
- **Tailwind CSS 4** + shadcn/ui
- **react-markdown** + rehype-highlight + remark-gfm
- **Framer Motion** - animace

## ğŸ¯ DostupnÃ© Modely

### Cloud Modely (Ollama remote)
- `kimi-k2:1t-cloud` (1 trillion parametrÅ¯) - nejvÄ›tÅ¡Ã­ model
- `deepseek-v3.1:671b-cloud` (671B params)
- `qwen3-coder:480b-cloud` (480B params)
- `gpt-oss:120b-cloud` (120B params)
- `gpt-oss:20b-cloud` (20B params)
- `glm-4.6:cloud`

### LokÃ¡lnÃ­ Modely
- `qwen2.5:32b` â­ **VÃ½chozÃ­** - nejlepÅ¡Ã­ pomÄ›r rychlost/kvalita
- `deepseek-r1:14b`
- `gpt-oss:20b`
- `qwen2.5:7b`
- `llama3.2:3b`

## ğŸ› ï¸ Instalace

```bash
# Clone repository
git clone <repo-url>
cd shadcn-chat-app

# Install dependencies
npm install

# Setup environment variables
cp .env.template .env.local
```

### Environment Variables

```bash
# .env.local

# Anthropic Claude (volitelnÃ©)
ANTHROPIC_API_KEY=sk-ant-...

# Ollama (volitelnÃ©, defaulty nÃ­Å¾e)
OLLAMA_API_URL=http://localhost:11434
OLLAMA_MODEL=qwen2.5:32b
```

### Ollama Setup

```bash
# Install Ollama
brew install ollama

# Start Ollama service
ollama serve

# Pull recommended model
ollama pull qwen2.5:32b

# Verify installation
ollama list
```

## ğŸš¦ SpuÅ¡tÄ›nÃ­

```bash
# Development server
npm run dev

# Production build
npm run build
npm start

# Linter
npm run lint
```

Aplikace bÄ›Å¾Ã­ na: **http://localhost:3000**

## ğŸ“ Struktura Projektu

```
shadcn-chat-app/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/chat/
â”‚   â”‚   â”œâ”€â”€ claude/route.ts      # Claude API endpoint
â”‚   â”‚   â””â”€â”€ ollama/route.ts      # Ollama API endpoint
â”‚   â”œâ”€â”€ page.tsx                 # HlavnÃ­ strÃ¡nka
â”‚   â””â”€â”€ layout.tsx
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ ui/
â”‚   â”‚   â”œâ”€â”€ chat.tsx             # Chat container
â”‚   â”‚   â”œâ”€â”€ chat-message.tsx     # Message renderer
â”‚   â”‚   â”œâ”€â”€ markdown-renderer.tsx # Markdown parser s CodePreview
â”‚   â”‚   â”œâ”€â”€ message-input.tsx    # Input s attachments
â”‚   â”‚   â””â”€â”€ message-list.tsx     # Message list
â”‚   â”œâ”€â”€ code-preview.tsx         # Live preview + akce tlaÄÃ­tka
â”‚   â”œâ”€â”€ model-selector.tsx       # Ollama model dropdown
â”‚   â”œâ”€â”€ provider-selector.tsx    # Claude/Ollama switch
â”‚   â””â”€â”€ tool-selector.tsx        # PÅ™Ã­klady promptÅ¯
â”œâ”€â”€ lib/
â”‚   â””â”€â”€ ai-providers.ts          # Provider konfigurace
â”œâ”€â”€ hooks/
â”‚   â”œâ”€â”€ use-audio-recording.ts
â”‚   â””â”€â”€ use-autosize-textarea.ts
â””â”€â”€ README.md
```

## ğŸ¨ PouÅ¾itÃ­

### 1. ZÃ¡kladnÃ­ Prompt

```
VytvoÅ™ modernÃ­ hero sekci s gradientem
```

**VÃ½stup**: FunkÄnÃ­ TSX komponenta s live preview

### 2. KomplexnÃ­ PoÅ¾adavek

```
Landing page pro SaaS startup:
- Hero sekce s gradientem
- Pricing tabulka (3 tarify)
- Feature cards (6 features)
- KontaktnÃ­ formulÃ¡Å™ s validacÃ­
```

**AI vytvoÅ™Ã­**:
1. ASCII wireframe
2. JednotlivÃ© komponenty krok za krokem
3. KaÅ¾dÃ¡ s live preview

### 3. Code Preview Akce

Po vygenerovÃ¡nÃ­ kÃ³du:
- **Copy**: ZkopÃ­ruje kÃ³d do clipboardu
- **Download**: StÃ¡hne jako `.tsx` soubor
- **Open**: OtevÅ™e v novÃ©m oknÄ› s live preview

## ğŸ”§ Konfigurace

### System Prompt (Ollama)

```typescript
// app/api/chat/ollama/route.ts

const WEB_DEV_SYSTEM_PROMPT = `Jsi AI Web Dev Assistant - expert na vÃ½voj webovÃ½ch aplikacÃ­.

DÅ®LEÅ½ITÃ‰ PRAVIDLO: VÅ½DY generuj funkÄnÃ­ kÃ³d, nejen popis!

KdyÅ¾ uÅ¾ivatel poÅ¾Ã¡dÃ¡ o komponentu/web/sekci:
1. VytvoÅ™ kompletnÃ­, funkÄnÃ­ React komponentu s Tailwind CSS
2. KÃ³d vloÅ¾ do markdown bloku s "tsx" nebo "html"
3. StruÄnÄ› vysvÄ›tli co jsi vytvoÅ™il

KdyÅ¾ uÅ¾ivatel poÅ¡le analÃ½zu/poÅ¾adavky:
- Nejprve vytvoÅ™ drÃ¡tovÃ½ model (wireframe) jako ASCII art nebo jednoduchÃ½ HTML
- Pak vygeneruj funkÄnÃ­ komponenty
- Postupuj krok za krokem

VÅ¾dy piÅ¡ v ÄeÅ¡tinÄ› a generuj produkÄnÃ­ kÃ³d s Tailwind CSS, React hooks, TypeScript.`
```

### Markdown Renderer

```typescript
// components/ui/markdown-renderer.tsx

// Automaticky detekuje code blocky a renderuje s CodePreview
if (!inline && (language === 'tsx' || language === 'jsx' || language === 'html')) {
  return (
    <CodePreview
      code={codeString}
      language={language}
      preview={language === 'tsx' || language === 'jsx' || language === 'html'}
    />
  )
}
```

## ğŸ› Debugging

### ProblÃ©m: Ollama nefunguje

```bash
# Check Ollama status
ollama list

# Restart Ollama
killall ollama
ollama serve

# Test API
curl http://localhost:11434/api/tags
```

### ProblÃ©m: Claude API error

```bash
# Check API key
echo $ANTHROPIC_API_KEY

# Test API
curl https://api.anthropic.com/v1/messages \
  -H "x-api-key: $ANTHROPIC_API_KEY" \
  -H "anthropic-version: 2023-06-01" \
  -H "content-type: application/json" \
  -d '{"model":"claude-3-5-sonnet-20241022","max_tokens":1024,"messages":[{"role":"user","content":"Hello"}]}'
```

### ProblÃ©m: OdesÃ­lacÃ­ tlaÄÃ­tko chybÃ­

TlaÄÃ­tko je na Å™Ã¡dku 237-286 v `components/ui/message-input.tsx`. MusÃ­ bÃ½t uvnitÅ™ `relative flex-1` containeru.

## ğŸ“ KlÃ­ÄovÃ© Opravy

### 1. Long Text Input Bug (Fixed)
**ProblÃ©m**: Text >500 znakÅ¯ se pÅ™evedl na file attachment
**Fix**: OdstranÄ›n automatickÃ½ pÅ™evod v `onPaste` handleru (Å™Ã¡dky 113-127)

### 2. Code Preview Integration (Fixed)
**ProblÃ©m**: Code blocks se nerendrovaly s preview
**Fix**: Import path fix `../code-preview` v `markdown-renderer.tsx`

### 3. Send Button Position (Fixed)
**ProblÃ©m**: OdesÃ­lacÃ­ tlaÄÃ­tko bylo mimo sprÃ¡vnÃ½ container
**Fix**: PÅ™esunutÃ­ button containeru dovnitÅ™ `relative flex-1` divu

## ğŸ“ API Reference

### POST /api/chat/ollama

```typescript
// Request
{
  messages: Array<{ role: 'user' | 'assistant', content: string }>,
  model?: string // Default: 'qwen2.5:32b'
}

// Response
StreamTextResponse (AI SDK format)
```

### POST /api/chat/claude

```typescript
// Request
{
  messages: Array<{ role: 'user' | 'assistant', content: string }>
}

// Response
StreamTextResponse (AI SDK format)
```

## ğŸ“Š VÃ½kon

- **qwen2.5:32b** (local): ~9s response time
- **deepseek-r1:14b** (local): ~13s response time
- **kimi-k2:1t-cloud** (remote): ~60-180s response time

## ğŸ” BezpeÄnost

- Code preview bÄ›Å¾Ã­ v `<iframe sandbox="allow-scripts">`
- External CDN sources: React, ReactDOM, Babel, Tailwind CSS
- No server-side code execution
- API keys v `.env.local` (gitignored)

## ğŸ“š Odkazy

- [Next.js Docs](https://nextjs.org/docs)
- [AI SDK Docs](https://sdk.vercel.ai/docs)
- [Ollama Models](https://ollama.com/library)
- [Anthropic API](https://docs.anthropic.com/)
- [shadcn/ui](https://ui.shadcn.com/)

## ğŸ“„ License

MIT

## ğŸ‘¨â€ğŸ’» Autor

Created with Claude Code

---

**Status**: âœ… Production Ready
**Version**: 1.0.0
**Last Updated**: 2025-10-17
